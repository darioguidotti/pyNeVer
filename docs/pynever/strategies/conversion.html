<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>pynever.strategies.conversion API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>pynever.strategies.conversion</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import copy
import abc
import pynever.networks as networks
import pynever.nodes as nodes
import torch
import onnx
import onnx.numpy_helper


class AlternativeRepresentation(abc.ABC):
    &#34;&#34;&#34;
    An abstract class used to represent an alternative representation for a neural network.

    Attributes
    ----------
    identifier : str
        identifier for the alternative representation
    up_to_date : bool, optional
        flag which indicates if the alternative representation is up to date with respect
        to the internal representation of the network (optional: True).

    &#34;&#34;&#34;
    def __init__(self, identifier: str, up_to_date: bool = True):
        self.identifier = identifier
        self.up_to_date = up_to_date


class ONNXNetwork(AlternativeRepresentation):
    &#34;&#34;&#34;
    An class used to represent a ONNX representation for a neural network.

    Attributes
    ----------
    identifier : str
        identifier for the alternative representation
    onnx_network : onnx.ModelProto
        Real ONNX network.
    up_to_date : bool
        flag which indicates if the alternative representation is up to date with respect
        to the internal representation of the network (optional: True).

    &#34;&#34;&#34;

    def __init__(self, identifier: str, onnx_network: onnx.ModelProto, up_to_date: bool = True):
        super().__init__(identifier, up_to_date)
        self.onnx_network = copy.deepcopy(onnx_network)


class PyTorchNetwork(AlternativeRepresentation):
    &#34;&#34;&#34;
    An class used to represent a PyTorch representation for a neural network.

    Attributes
    ----------
    identifier : str
        identifier for the alternative representation
    pytorch_network : torch.nn.Module
        Real PyTorch network.
    up_to_date : bool
        flag which indicates if the alternative representation is up to date with respect
        to the internal representation of the network (optional: True).

    &#34;&#34;&#34;
    def __init__(self, identifier: str, pytorch_network: torch.nn.Module, up_to_date: bool = True):
        super().__init__(identifier, up_to_date)
        self.pytorch_network = copy.deepcopy(pytorch_network)


class TensorflowNetwork(AlternativeRepresentation):
    &#34;&#34;&#34;
    An class used to represent a Tensorflow representation for a neural network.

    Attributes
    ----------
    identifier : str
        identifier for the alternative representation
    up_to_date : bool
        flag which indicates if the alternative representation is up to date with respect
        to the internal representation of the network (optional: True).

    &#34;&#34;&#34;
    def __init__(self, identifier: str, up_to_date: bool = True):
        super().__init__(identifier, up_to_date)


class ConversionStrategy(abc.ABC):
    &#34;&#34;&#34;
    An abstract class used to represent a Conversion Strategy.

    Methods
    ----------
    from_neural_network(NeuralNetwork)
        Convert the neural network of interest to an alternative representation determined in the concrete children.
    to_neural_network(AlternativeRepresentation)
        Convert the alternative representation of interest to our internal representation of a Neural Network.

    &#34;&#34;&#34;

    @abc.abstractmethod
    def from_neural_network(self, network: networks.NeuralNetwork) -&gt; AlternativeRepresentation:
        &#34;&#34;&#34;
        Convert the neural network of interest to an alternative representation determined in the concrete children.

        Parameters
        ----------
        network : NeuralNetwork
            The neural network to convert.

        Returns
        ----------
        AlternativeRepresentation
            The alternative representation resulting from the conversion of the original network.
        &#34;&#34;&#34;
        pass

    @abc.abstractmethod
    def to_neural_network(self, alt_rep: AlternativeRepresentation) -&gt; networks.NeuralNetwork:
        &#34;&#34;&#34;
        Convert the alternative representation of interest to the internal one.

        Parameters
        ----------
        alt_rep : AlternativeRepresentation
            The Alternative Representation to convert.

        Returns
        ----------
        NeuralNetwork
            The Neural Network resulting from the conversion of Alternative Representation.
        &#34;&#34;&#34;
        pass


class ONNXConverter(ConversionStrategy):
    &#34;&#34;&#34;
    A class used to represent the conversion strategy for ONNX models.

    Methods
    ----------
    from_neural_network(NeuralNetwork)
        Convert the neural network of interest to a ONNXNetwork model.
    to_neural_network(ONNXNetwork)
        Convert the ONNXNetwork of interest to our internal representation of a Neural Network.

    &#34;&#34;&#34;

    def from_neural_network(self, network: networks.NeuralNetwork) -&gt; ONNXNetwork:
        &#34;&#34;&#34;
        Convert the neural network of interest to a ONNX representation.

        Parameters
        ----------
        network : NeuralNetwork
            The neural network to convert.

        Returns
        ----------
        ONNXNetwork
            The ONNX representation resulting from the conversion of the original network.

        &#34;&#34;&#34;

        alt_net = None
        for alt_rep in network.alt_rep_cache:
            if isinstance(alt_rep, ONNXNetwork) and alt_rep.up_to_date:
                alt_net = alt_rep

        if alt_net is None:

            if not network.up_to_date:

                for alt_rep in network.alt_rep_cache:

                    if alt_rep.up_to_date:

                        if isinstance(alt_rep, PyTorchNetwork):
                            pytorch_cv = PyTorchConverter()
                            network = pytorch_cv.to_neural_network(alt_rep)

                        else:
                            raise NotImplementedError
                        break

            if isinstance(network, networks.SequentialNetwork):

                current_node = None
                previous_output = &#39;X&#39;
                input_info = []
                output_info = []
                initializers = []
                onnx_nodes = []

                while network.get_next_node(current_node) is not None:

                    current_node = network.get_next_node(current_node)
                    current_input = previous_output

                    if network.get_next_node(current_node) is None:
                        current_output = &#39;Y&#39;
                    else:
                        current_output = current_node.identifier + &#39;_output&#39;

                    if isinstance(current_node, nodes.ReLUNode):

                        input_size = output_size = current_node.num_features
                        input_value_info = onnx.helper.make_tensor_value_info(current_input, onnx.TensorProto.FLOAT,
                                                                              [1, input_size])
                        output_value_info = onnx.helper.make_tensor_value_info(current_output, onnx.TensorProto.FLOAT,
                                                                               [1, output_size])

                        onnx_node = onnx.helper.make_node(
                            &#39;Relu&#39;,
                            inputs=[current_input],
                            outputs=[current_output],
                        )

                        input_info.append(input_value_info)
                        output_info.append(output_value_info)
                        onnx_nodes.append(onnx_node)

                    elif isinstance(current_node, nodes.SigmoidNode):

                        input_size = output_size = current_node.num_features
                        input_value_info = onnx.helper.make_tensor_value_info(current_input, onnx.TensorProto.FLOAT,
                                                                              [1, input_size])
                        output_value_info = onnx.helper.make_tensor_value_info(current_output, onnx.TensorProto.FLOAT,
                                                                               [1, output_size])

                        onnx_node = onnx.helper.make_node(
                            &#39;Sigmoid&#39;,
                            inputs=[current_input],
                            outputs=[current_output],
                        )

                        input_info.append(input_value_info)
                        output_info.append(output_value_info)
                        onnx_nodes.append(onnx_node)

                    elif isinstance(current_node, nodes.FullyConnectedNode):

                        input_size = current_node.in_features
                        output_size = current_node.out_features

                        input_weight = current_node.identifier + &#34;_weight&#34;
                        input_bias = current_node.identifier + &#34;_bias&#34;

                        input_value_info = onnx.helper.make_tensor_value_info(current_input, onnx.TensorProto.FLOAT,
                                                                              [1, input_size])
                        output_value_info = onnx.helper.make_tensor_value_info(current_output, onnx.TensorProto.FLOAT,
                                                                               [1, output_size])
                        weight_value_info = onnx.helper.make_tensor_value_info(input_weight, onnx.TensorProto.FLOAT,
                                                                               [output_size, input_size])
                        bias_value_info = onnx.helper.make_tensor_value_info(input_bias, onnx.TensorProto.FLOAT,
                                                                             [output_size])

                        # N.B: The Marabou procedure for reading ONNX models do not consider the attributes
                        # transA and transB, therefore we need to transpose the weight vector.
                        weight_tensor = onnx.numpy_helper.from_array(current_node.weight.T, input_weight)
                        bias_tensor = onnx.numpy_helper.from_array(current_node.bias, input_bias)

                        onnx_node = onnx.helper.make_node(
                            &#39;Gemm&#39;,
                            inputs=[current_input, input_weight, input_bias],
                            outputs=[current_output],
                            alpha=1.0,
                            beta=1.0,
                            transA=0,
                            transB=0
                        )

                        input_info.append(input_value_info)
                        input_info.append(weight_value_info)
                        input_info.append(bias_value_info)

                        output_info.append(output_value_info)

                        initializers.append(weight_tensor)
                        initializers.append(bias_tensor)

                        onnx_nodes.append(onnx_node)

                    elif isinstance(current_node, nodes.BatchNorm1DNode):

                        input_size = output_size = current_node.num_features

                        input_scale = current_node.identifier + &#34;_scale&#34;
                        input_bias = current_node.identifier + &#34;_bias&#34;
                        input_mean = current_node.identifier + &#34;_mean&#34;
                        input_var = current_node.identifier + &#34;_var&#34;

                        input_value_info = onnx.helper.make_tensor_value_info(current_input, onnx.TensorProto.FLOAT,
                                                                              [1, input_size])
                        output_value_info = onnx.helper.make_tensor_value_info(current_output, onnx.TensorProto.FLOAT,
                                                                               [1, output_size])
                        scale_value_info = onnx.helper.make_tensor_value_info(input_scale, onnx.TensorProto.FLOAT,
                                                                              [input_size])
                        bias_value_info = onnx.helper.make_tensor_value_info(input_bias, onnx.TensorProto.FLOAT,
                                                                             [input_size])
                        mean_value_info = onnx.helper.make_tensor_value_info(input_mean, onnx.TensorProto.FLOAT,
                                                                             [input_size])
                        var_value_info = onnx.helper.make_tensor_value_info(input_var, onnx.TensorProto.FLOAT,
                                                                            [input_size])

                        scale_tensor = onnx.numpy_helper.from_array(current_node.weight, input_scale)
                        bias_tensor = onnx.numpy_helper.from_array(current_node.bias, input_bias)
                        mean_tensor = onnx.numpy_helper.from_array(current_node.running_mean, input_mean)
                        var_tensor = onnx.numpy_helper.from_array(current_node.running_var, input_var)

                        onnx_node = onnx.helper.make_node(
                            &#39;BatchNormalization&#39;,
                            inputs=[current_input, input_scale, input_bias, input_mean, input_var],
                            outputs=[current_output],
                            epsilon=current_node.eps,
                            momentum=current_node.momentum
                        )

                        input_info.append(input_value_info)
                        input_info.append(scale_value_info)
                        input_info.append(bias_value_info)
                        input_info.append(mean_value_info)
                        input_info.append(var_value_info)

                        output_info.append(output_value_info)

                        initializers.append(scale_tensor)
                        initializers.append(bias_tensor)
                        initializers.append(mean_tensor)
                        initializers.append(var_tensor)

                        onnx_nodes.append(onnx_node)

                    else:
                        raise NotImplementedError

                    previous_output = current_output

                onnx_graph = onnx.helper.make_graph(
                    nodes=onnx_nodes,
                    name=network.identifier,
                    inputs=[input_info[0]],
                    outputs=[output_info[-1]],
                    initializer=initializers,
                    value_info=input_info
                )

                onnx_network = onnx.helper.make_model(graph=onnx_graph)
                alt_net = ONNXNetwork(network.identifier + &#34;_onnx&#34;, onnx_network)

            else:
                raise NotImplementedError

        return alt_net

    def to_neural_network(self, alt_rep: ONNXNetwork) -&gt; networks.NeuralNetwork:
        &#34;&#34;&#34;
        Convert the ONNX representation of interest to the internal one.

        Parameters
        ----------
        alt_rep : ONNXNetwork
            The ONNX Representation to convert.

        Returns
        ----------
        NeuralNetwork
            The Neural Network resulting from the conversion of ONNX Representation.

        &#34;&#34;&#34;
        identifier = alt_rep.identifier.replace(&#34;_onnx&#34;, &#34;&#34;)
        network = networks.SequentialNetwork(identifier)

        parameters = {}
        for initializer in alt_rep.onnx_network.graph.initializer:
            parameters[initializer.name] = onnx.numpy_helper.to_array(initializer)

        shape_info = {}
        for value_info in alt_rep.onnx_network.graph.value_info:
            shape = []
            for dim in value_info.type.tensor_type.shape.dim:
                shape.append(dim.dim_value)
            shape_info[value_info.name] = shape

        node_index = 1
        for node in alt_rep.onnx_network.graph.node:

            if node.op_type == &#34;Relu&#34;:

                # We assume that the real input of the node is always the first element of node.input
                # and that the shape is [batch_placeholder, real_size] for the inputs.
                num_features = shape_info[node.input[0]][1]
                network.add_node(nodes.ReLUNode(f&#34;ReLU_{node_index}&#34;, num_features))

            elif node.op_type == &#34;Sigmoid&#34;:
                num_features = shape_info[node.input[0]][1]
                network.add_node(nodes.SigmoidNode(f&#34;Sigmoid_{node_index}&#34;, num_features))

            elif node.op_type == &#34;Gemm&#34;:
                # We assume that the weight tensor is always the second element of node.input and the bias tensor
                # is always the third.
                # N.B: The Marabou procedure for reading ONNX models do not consider the attributes transA and transB,
                # therefore we need to transpose the weight vector.
                weight = parameters[node.input[1]].T
                bias = parameters[node.input[2]]
                in_features = weight.shape[1]
                out_features = weight.shape[0]
                network.add_node(nodes.FullyConnectedNode(f&#34;Linear_{node_index}&#34;, in_features,
                                                          out_features, weight, bias))
            elif node.op_type == &#34;BatchNormalization&#34;:
                # We assume that the real input is always the first element of node.input, the weight tensor
                # is always the second, the bias tensor is always the third, the running_mean always the fourth
                # and the running_var always the fifth.
                num_features = shape_info[node.input[0]][1]
                weight = parameters[node.input[1]]
                bias = parameters[node.input[2]]
                running_mean = parameters[node.input[3]]
                running_var = parameters[node.input[4]]
                # We assume that eps is always the first attribute and momentum is always the second.
                eps = node.attribute[0].f
                momentum = node.attribute[1].f
                network.add_node(nodes.BatchNorm1DNode(f&#34;BatchNorm_{node_index}&#34;, num_features, weight, bias,
                                                       running_mean, running_var, eps, momentum))

            else:
                raise NotImplementedError

            node_index += 1

        return network


class PyTorchConverter(ConversionStrategy):
    &#34;&#34;&#34;
    A class used to represent the conversion strategy for PyTorch models.

    Methods
    ----------
    from_neural_network(NeuralNetwork)
        Convert the neural network of interest to a PyTorchNetwork model.
    to_neural_network(PyTorchNetwork)
        Convert the PyTorchNetwork of interest to our internal representation of a Neural Network.

    &#34;&#34;&#34;

    def from_neural_network(self, network: networks.NeuralNetwork) -&gt; PyTorchNetwork:
        &#34;&#34;&#34;
        Convert the neural network of interest to a PyTorch representation.

        Parameters
        ----------
        network : NeuralNetwork
            The neural network to convert.

        Returns
        ----------
        PyTorchNetwork
            The PyTorch representation resulting from the conversion of the original network.

        &#34;&#34;&#34;

        alt_net = None
        pytorch_network = None
        for alt_rep in network.alt_rep_cache:
            if isinstance(alt_rep, PyTorchNetwork) and alt_rep.up_to_date:
                alt_net = alt_rep

        if alt_net is None:

            if not network.up_to_date:

                for alt_rep in network.alt_rep_cache:

                    if alt_rep.up_to_date:

                        if isinstance(alt_rep, ONNXNetwork):
                            onnx_cv = ONNXConverter()
                            network = onnx_cv.to_neural_network(alt_rep)

                        else:
                            raise NotImplementedError
                        break

            if isinstance(network, networks.SequentialNetwork):
                pytorch_layers = []
                for layer in network.nodes.values():

                    new_layer = None
                    if isinstance(layer, nodes.ReLUNode):
                        new_layer = torch.nn.ReLU()

                    elif isinstance(layer, nodes.SigmoidNode):
                        new_layer = torch.nn.Sigmoid()

                    elif isinstance(layer, nodes.FullyConnectedNode):

                        if layer.bias is not None:
                            has_bias = True
                        else:
                            has_bias = False

                        new_layer = torch.nn.Linear(in_features=layer.in_features,
                                                    out_features=layer.out_features,
                                                    bias=has_bias)

                        weight = torch.from_numpy(layer.weight)
                        new_layer.weight.data = weight

                        if has_bias:
                            bias = torch.from_numpy(layer.bias)
                            new_layer.bias.data = bias

                    elif isinstance(layer, nodes.BatchNorm1DNode):

                        new_layer = torch.nn.BatchNorm1d(num_features=layer.num_features,
                                                         eps=layer.eps, momentum=layer.momentum,
                                                         affine=layer.affine,
                                                         track_running_stats=layer.track_running_stats)

                        new_layer.weight.data = torch.from_numpy(layer.weight)
                        new_layer.bias.data = torch.from_numpy(layer.bias)
                        new_layer.running_mean.data = torch.from_numpy(layer.running_mean)
                        new_layer.running_var.data = torch.from_numpy(layer.running_var)

                    if new_layer is not None:
                        pytorch_layers.append(new_layer)

                pytorch_network = torch.nn.Sequential(*pytorch_layers)

            if alt_net is None and pytorch_network is None:
                print(&#34;WARNING: network to convert is not valid, the alternative representation is None&#34;)

            identifier = network.identifier + &#39;_pytorch&#39;
            alt_net = PyTorchNetwork(identifier=identifier, pytorch_network=pytorch_network)

        return alt_net

    def to_neural_network(self, alt_rep: PyTorchNetwork) -&gt; networks.NeuralNetwork:
        &#34;&#34;&#34;
        Convert the PyTorch representation of interest to the internal one.

        Parameters
        ----------
        alt_rep : PyTorchNetwork
            The PyTorch Representation to convert.

        Returns
        ----------
        NeuralNetwork
            The Neural Network resulting from the conversion of PyTorch Representation.

        &#34;&#34;&#34;

        identifier = alt_rep.identifier.replace(&#39;_pytorch&#39;, &#39;&#39;)
        network = networks.SequentialNetwork(identifier=identifier)

        node_index = 0
        size_prev_output = 0
        alt_rep.pytorch_network.cpu()
        for m in alt_rep.pytorch_network.modules():

            new_node = None

            if isinstance(m, torch.nn.ReLU):
                new_node = nodes.ReLUNode(identifier=&#39;ReLU_{}&#39;.format(node_index), num_features=size_prev_output)

            elif isinstance(m, torch.nn.Sigmoid):
                new_node = nodes.SigmoidNode(identifier=&#39;Sigmoid_{}&#39;.format(node_index), num_features=size_prev_output)

            elif isinstance(m, torch.nn.Linear):
                in_features = m.in_features
                out_features = m.out_features
                weight = m.weight.detach().numpy()
                bias = m.bias.detach().numpy()
                new_node = nodes.FullyConnectedNode(identifier=&#39;FullyConnected_{}&#39;.format(node_index),
                                                    in_features=in_features, out_features=out_features,
                                                    weight=weight, bias=bias)

                size_prev_output = out_features

            elif isinstance(m, torch.nn.BatchNorm1d):

                num_features = m.num_features
                eps = m.eps
                momentum = m.momentum
                track_running_stats = m.track_running_stats
                affine = m.affine

                weight = m.weight.detach().numpy()
                bias = m.bias.detach().numpy()
                running_mean = m.running_mean.numpy()
                running_var = m.running_var.numpy()

                new_node = nodes.BatchNorm1DNode(identifier=&#39;BatchNorm1D_{}&#39;.format(node_index),
                                                 num_features=num_features, weight=weight, bias=bias,
                                                 running_mean=running_mean, running_var=running_var, eps=eps,
                                                 momentum=momentum, affine=affine,
                                                 track_running_stats=track_running_stats)

                size_prev_output = num_features

            if new_node is not None:
                node_index += 1
                network.add_node(new_node)

        return network


class TensorflowConverter(ConversionStrategy):
    &#34;&#34;&#34;
    A class used to represent the conversion strategy for Tensorflow models.

    Methods
    ----------
    from_neural_network(NeuralNetwork)
        Convert the neural network of interest to a TensorflowNetwork model.
    to_neural_network(ONNXNetwork)
        Convert the TensorflowNetwork of interest to our internal representation of a Neural Network.

    &#34;&#34;&#34;

    def from_neural_network(self, network: networks.NeuralNetwork) -&gt; TensorflowNetwork:
        &#34;&#34;&#34;
        Convert the neural network of interest to a Tensorflow representation.

        Parameters
        ----------
        network : NeuralNetwork
            The neural network to convert.

        Returns
        ----------
        TensorflowNetwork
            The Tensorflow representation resulting from the conversion of the original network.

        &#34;&#34;&#34;

    def to_neural_network(self, alt_rep: TensorflowNetwork) -&gt; networks.NeuralNetwork:
        &#34;&#34;&#34;
        Convert the Tensorflow representation of interest to the internal one.

        Parameters
        ----------
        alt_rep : TensorflowNetwork
            The Tensorflow Representation to convert.

        Returns
        ----------
        NeuralNetwork
            The Neural Network resulting from the conversion of Tensorflow Representation.

        &#34;&#34;&#34;</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="pynever.strategies.conversion.AlternativeRepresentation"><code class="flex name class">
<span>class <span class="ident">AlternativeRepresentation</span></span>
<span>(</span><span>identifier: str, up_to_date: bool = True)</span>
</code></dt>
<dd>
<div class="desc"><p>An abstract class used to represent an alternative representation for a neural network.</p>
<h2 id="attributes">Attributes</h2>
<dl>
<dt><strong><code>identifier</code></strong> :&ensp;<code>str</code></dt>
<dd>identifier for the alternative representation</dd>
<dt><strong><code>up_to_date</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>flag which indicates if the alternative representation is up to date with respect
to the internal representation of the network (optional: True).</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class AlternativeRepresentation(abc.ABC):
    &#34;&#34;&#34;
    An abstract class used to represent an alternative representation for a neural network.

    Attributes
    ----------
    identifier : str
        identifier for the alternative representation
    up_to_date : bool, optional
        flag which indicates if the alternative representation is up to date with respect
        to the internal representation of the network (optional: True).

    &#34;&#34;&#34;
    def __init__(self, identifier: str, up_to_date: bool = True):
        self.identifier = identifier
        self.up_to_date = up_to_date</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>abc.ABC</li>
</ul>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="pynever.strategies.conversion.ONNXNetwork" href="#pynever.strategies.conversion.ONNXNetwork">ONNXNetwork</a></li>
<li><a title="pynever.strategies.conversion.PyTorchNetwork" href="#pynever.strategies.conversion.PyTorchNetwork">PyTorchNetwork</a></li>
<li><a title="pynever.strategies.conversion.TensorflowNetwork" href="#pynever.strategies.conversion.TensorflowNetwork">TensorflowNetwork</a></li>
</ul>
</dd>
<dt id="pynever.strategies.conversion.ConversionStrategy"><code class="flex name class">
<span>class <span class="ident">ConversionStrategy</span></span>
</code></dt>
<dd>
<div class="desc"><p>An abstract class used to represent a Conversion Strategy.</p>
<h2 id="methods">Methods</h2>
<p>from_neural_network(NeuralNetwork)
Convert the neural network of interest to an alternative representation determined in the concrete children.
to_neural_network(AlternativeRepresentation)
Convert the alternative representation of interest to our internal representation of a Neural Network.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class ConversionStrategy(abc.ABC):
    &#34;&#34;&#34;
    An abstract class used to represent a Conversion Strategy.

    Methods
    ----------
    from_neural_network(NeuralNetwork)
        Convert the neural network of interest to an alternative representation determined in the concrete children.
    to_neural_network(AlternativeRepresentation)
        Convert the alternative representation of interest to our internal representation of a Neural Network.

    &#34;&#34;&#34;

    @abc.abstractmethod
    def from_neural_network(self, network: networks.NeuralNetwork) -&gt; AlternativeRepresentation:
        &#34;&#34;&#34;
        Convert the neural network of interest to an alternative representation determined in the concrete children.

        Parameters
        ----------
        network : NeuralNetwork
            The neural network to convert.

        Returns
        ----------
        AlternativeRepresentation
            The alternative representation resulting from the conversion of the original network.
        &#34;&#34;&#34;
        pass

    @abc.abstractmethod
    def to_neural_network(self, alt_rep: AlternativeRepresentation) -&gt; networks.NeuralNetwork:
        &#34;&#34;&#34;
        Convert the alternative representation of interest to the internal one.

        Parameters
        ----------
        alt_rep : AlternativeRepresentation
            The Alternative Representation to convert.

        Returns
        ----------
        NeuralNetwork
            The Neural Network resulting from the conversion of Alternative Representation.
        &#34;&#34;&#34;
        pass</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>abc.ABC</li>
</ul>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="pynever.strategies.conversion.ONNXConverter" href="#pynever.strategies.conversion.ONNXConverter">ONNXConverter</a></li>
<li><a title="pynever.strategies.conversion.PyTorchConverter" href="#pynever.strategies.conversion.PyTorchConverter">PyTorchConverter</a></li>
<li><a title="pynever.strategies.conversion.TensorflowConverter" href="#pynever.strategies.conversion.TensorflowConverter">TensorflowConverter</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="pynever.strategies.conversion.ConversionStrategy.from_neural_network"><code class="name flex">
<span>def <span class="ident">from_neural_network</span></span>(<span>self, network: <a title="pynever.networks.NeuralNetwork" href="../networks.html#pynever.networks.NeuralNetwork">NeuralNetwork</a>) ‑> <a title="pynever.strategies.conversion.AlternativeRepresentation" href="#pynever.strategies.conversion.AlternativeRepresentation">AlternativeRepresentation</a></span>
</code></dt>
<dd>
<div class="desc"><p>Convert the neural network of interest to an alternative representation determined in the concrete children.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>network</code></strong> :&ensp;<code>NeuralNetwork</code></dt>
<dd>The neural network to convert.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="pynever.strategies.conversion.AlternativeRepresentation" href="#pynever.strategies.conversion.AlternativeRepresentation">AlternativeRepresentation</a></code></dt>
<dd>The alternative representation resulting from the conversion of the original network.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@abc.abstractmethod
def from_neural_network(self, network: networks.NeuralNetwork) -&gt; AlternativeRepresentation:
    &#34;&#34;&#34;
    Convert the neural network of interest to an alternative representation determined in the concrete children.

    Parameters
    ----------
    network : NeuralNetwork
        The neural network to convert.

    Returns
    ----------
    AlternativeRepresentation
        The alternative representation resulting from the conversion of the original network.
    &#34;&#34;&#34;
    pass</code></pre>
</details>
</dd>
<dt id="pynever.strategies.conversion.ConversionStrategy.to_neural_network"><code class="name flex">
<span>def <span class="ident">to_neural_network</span></span>(<span>self, alt_rep: <a title="pynever.strategies.conversion.AlternativeRepresentation" href="#pynever.strategies.conversion.AlternativeRepresentation">AlternativeRepresentation</a>) ‑> <a title="pynever.networks.NeuralNetwork" href="../networks.html#pynever.networks.NeuralNetwork">NeuralNetwork</a></span>
</code></dt>
<dd>
<div class="desc"><p>Convert the alternative representation of interest to the internal one.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>alt_rep</code></strong> :&ensp;<code><a title="pynever.strategies.conversion.AlternativeRepresentation" href="#pynever.strategies.conversion.AlternativeRepresentation">AlternativeRepresentation</a></code></dt>
<dd>The Alternative Representation to convert.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>NeuralNetwork</code></dt>
<dd>The Neural Network resulting from the conversion of Alternative Representation.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@abc.abstractmethod
def to_neural_network(self, alt_rep: AlternativeRepresentation) -&gt; networks.NeuralNetwork:
    &#34;&#34;&#34;
    Convert the alternative representation of interest to the internal one.

    Parameters
    ----------
    alt_rep : AlternativeRepresentation
        The Alternative Representation to convert.

    Returns
    ----------
    NeuralNetwork
        The Neural Network resulting from the conversion of Alternative Representation.
    &#34;&#34;&#34;
    pass</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="pynever.strategies.conversion.ONNXConverter"><code class="flex name class">
<span>class <span class="ident">ONNXConverter</span></span>
</code></dt>
<dd>
<div class="desc"><p>A class used to represent the conversion strategy for ONNX models.</p>
<h2 id="methods">Methods</h2>
<p>from_neural_network(NeuralNetwork)
Convert the neural network of interest to a ONNXNetwork model.
to_neural_network(ONNXNetwork)
Convert the ONNXNetwork of interest to our internal representation of a Neural Network.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class ONNXConverter(ConversionStrategy):
    &#34;&#34;&#34;
    A class used to represent the conversion strategy for ONNX models.

    Methods
    ----------
    from_neural_network(NeuralNetwork)
        Convert the neural network of interest to a ONNXNetwork model.
    to_neural_network(ONNXNetwork)
        Convert the ONNXNetwork of interest to our internal representation of a Neural Network.

    &#34;&#34;&#34;

    def from_neural_network(self, network: networks.NeuralNetwork) -&gt; ONNXNetwork:
        &#34;&#34;&#34;
        Convert the neural network of interest to a ONNX representation.

        Parameters
        ----------
        network : NeuralNetwork
            The neural network to convert.

        Returns
        ----------
        ONNXNetwork
            The ONNX representation resulting from the conversion of the original network.

        &#34;&#34;&#34;

        alt_net = None
        for alt_rep in network.alt_rep_cache:
            if isinstance(alt_rep, ONNXNetwork) and alt_rep.up_to_date:
                alt_net = alt_rep

        if alt_net is None:

            if not network.up_to_date:

                for alt_rep in network.alt_rep_cache:

                    if alt_rep.up_to_date:

                        if isinstance(alt_rep, PyTorchNetwork):
                            pytorch_cv = PyTorchConverter()
                            network = pytorch_cv.to_neural_network(alt_rep)

                        else:
                            raise NotImplementedError
                        break

            if isinstance(network, networks.SequentialNetwork):

                current_node = None
                previous_output = &#39;X&#39;
                input_info = []
                output_info = []
                initializers = []
                onnx_nodes = []

                while network.get_next_node(current_node) is not None:

                    current_node = network.get_next_node(current_node)
                    current_input = previous_output

                    if network.get_next_node(current_node) is None:
                        current_output = &#39;Y&#39;
                    else:
                        current_output = current_node.identifier + &#39;_output&#39;

                    if isinstance(current_node, nodes.ReLUNode):

                        input_size = output_size = current_node.num_features
                        input_value_info = onnx.helper.make_tensor_value_info(current_input, onnx.TensorProto.FLOAT,
                                                                              [1, input_size])
                        output_value_info = onnx.helper.make_tensor_value_info(current_output, onnx.TensorProto.FLOAT,
                                                                               [1, output_size])

                        onnx_node = onnx.helper.make_node(
                            &#39;Relu&#39;,
                            inputs=[current_input],
                            outputs=[current_output],
                        )

                        input_info.append(input_value_info)
                        output_info.append(output_value_info)
                        onnx_nodes.append(onnx_node)

                    elif isinstance(current_node, nodes.SigmoidNode):

                        input_size = output_size = current_node.num_features
                        input_value_info = onnx.helper.make_tensor_value_info(current_input, onnx.TensorProto.FLOAT,
                                                                              [1, input_size])
                        output_value_info = onnx.helper.make_tensor_value_info(current_output, onnx.TensorProto.FLOAT,
                                                                               [1, output_size])

                        onnx_node = onnx.helper.make_node(
                            &#39;Sigmoid&#39;,
                            inputs=[current_input],
                            outputs=[current_output],
                        )

                        input_info.append(input_value_info)
                        output_info.append(output_value_info)
                        onnx_nodes.append(onnx_node)

                    elif isinstance(current_node, nodes.FullyConnectedNode):

                        input_size = current_node.in_features
                        output_size = current_node.out_features

                        input_weight = current_node.identifier + &#34;_weight&#34;
                        input_bias = current_node.identifier + &#34;_bias&#34;

                        input_value_info = onnx.helper.make_tensor_value_info(current_input, onnx.TensorProto.FLOAT,
                                                                              [1, input_size])
                        output_value_info = onnx.helper.make_tensor_value_info(current_output, onnx.TensorProto.FLOAT,
                                                                               [1, output_size])
                        weight_value_info = onnx.helper.make_tensor_value_info(input_weight, onnx.TensorProto.FLOAT,
                                                                               [output_size, input_size])
                        bias_value_info = onnx.helper.make_tensor_value_info(input_bias, onnx.TensorProto.FLOAT,
                                                                             [output_size])

                        # N.B: The Marabou procedure for reading ONNX models do not consider the attributes
                        # transA and transB, therefore we need to transpose the weight vector.
                        weight_tensor = onnx.numpy_helper.from_array(current_node.weight.T, input_weight)
                        bias_tensor = onnx.numpy_helper.from_array(current_node.bias, input_bias)

                        onnx_node = onnx.helper.make_node(
                            &#39;Gemm&#39;,
                            inputs=[current_input, input_weight, input_bias],
                            outputs=[current_output],
                            alpha=1.0,
                            beta=1.0,
                            transA=0,
                            transB=0
                        )

                        input_info.append(input_value_info)
                        input_info.append(weight_value_info)
                        input_info.append(bias_value_info)

                        output_info.append(output_value_info)

                        initializers.append(weight_tensor)
                        initializers.append(bias_tensor)

                        onnx_nodes.append(onnx_node)

                    elif isinstance(current_node, nodes.BatchNorm1DNode):

                        input_size = output_size = current_node.num_features

                        input_scale = current_node.identifier + &#34;_scale&#34;
                        input_bias = current_node.identifier + &#34;_bias&#34;
                        input_mean = current_node.identifier + &#34;_mean&#34;
                        input_var = current_node.identifier + &#34;_var&#34;

                        input_value_info = onnx.helper.make_tensor_value_info(current_input, onnx.TensorProto.FLOAT,
                                                                              [1, input_size])
                        output_value_info = onnx.helper.make_tensor_value_info(current_output, onnx.TensorProto.FLOAT,
                                                                               [1, output_size])
                        scale_value_info = onnx.helper.make_tensor_value_info(input_scale, onnx.TensorProto.FLOAT,
                                                                              [input_size])
                        bias_value_info = onnx.helper.make_tensor_value_info(input_bias, onnx.TensorProto.FLOAT,
                                                                             [input_size])
                        mean_value_info = onnx.helper.make_tensor_value_info(input_mean, onnx.TensorProto.FLOAT,
                                                                             [input_size])
                        var_value_info = onnx.helper.make_tensor_value_info(input_var, onnx.TensorProto.FLOAT,
                                                                            [input_size])

                        scale_tensor = onnx.numpy_helper.from_array(current_node.weight, input_scale)
                        bias_tensor = onnx.numpy_helper.from_array(current_node.bias, input_bias)
                        mean_tensor = onnx.numpy_helper.from_array(current_node.running_mean, input_mean)
                        var_tensor = onnx.numpy_helper.from_array(current_node.running_var, input_var)

                        onnx_node = onnx.helper.make_node(
                            &#39;BatchNormalization&#39;,
                            inputs=[current_input, input_scale, input_bias, input_mean, input_var],
                            outputs=[current_output],
                            epsilon=current_node.eps,
                            momentum=current_node.momentum
                        )

                        input_info.append(input_value_info)
                        input_info.append(scale_value_info)
                        input_info.append(bias_value_info)
                        input_info.append(mean_value_info)
                        input_info.append(var_value_info)

                        output_info.append(output_value_info)

                        initializers.append(scale_tensor)
                        initializers.append(bias_tensor)
                        initializers.append(mean_tensor)
                        initializers.append(var_tensor)

                        onnx_nodes.append(onnx_node)

                    else:
                        raise NotImplementedError

                    previous_output = current_output

                onnx_graph = onnx.helper.make_graph(
                    nodes=onnx_nodes,
                    name=network.identifier,
                    inputs=[input_info[0]],
                    outputs=[output_info[-1]],
                    initializer=initializers,
                    value_info=input_info
                )

                onnx_network = onnx.helper.make_model(graph=onnx_graph)
                alt_net = ONNXNetwork(network.identifier + &#34;_onnx&#34;, onnx_network)

            else:
                raise NotImplementedError

        return alt_net

    def to_neural_network(self, alt_rep: ONNXNetwork) -&gt; networks.NeuralNetwork:
        &#34;&#34;&#34;
        Convert the ONNX representation of interest to the internal one.

        Parameters
        ----------
        alt_rep : ONNXNetwork
            The ONNX Representation to convert.

        Returns
        ----------
        NeuralNetwork
            The Neural Network resulting from the conversion of ONNX Representation.

        &#34;&#34;&#34;
        identifier = alt_rep.identifier.replace(&#34;_onnx&#34;, &#34;&#34;)
        network = networks.SequentialNetwork(identifier)

        parameters = {}
        for initializer in alt_rep.onnx_network.graph.initializer:
            parameters[initializer.name] = onnx.numpy_helper.to_array(initializer)

        shape_info = {}
        for value_info in alt_rep.onnx_network.graph.value_info:
            shape = []
            for dim in value_info.type.tensor_type.shape.dim:
                shape.append(dim.dim_value)
            shape_info[value_info.name] = shape

        node_index = 1
        for node in alt_rep.onnx_network.graph.node:

            if node.op_type == &#34;Relu&#34;:

                # We assume that the real input of the node is always the first element of node.input
                # and that the shape is [batch_placeholder, real_size] for the inputs.
                num_features = shape_info[node.input[0]][1]
                network.add_node(nodes.ReLUNode(f&#34;ReLU_{node_index}&#34;, num_features))

            elif node.op_type == &#34;Sigmoid&#34;:
                num_features = shape_info[node.input[0]][1]
                network.add_node(nodes.SigmoidNode(f&#34;Sigmoid_{node_index}&#34;, num_features))

            elif node.op_type == &#34;Gemm&#34;:
                # We assume that the weight tensor is always the second element of node.input and the bias tensor
                # is always the third.
                # N.B: The Marabou procedure for reading ONNX models do not consider the attributes transA and transB,
                # therefore we need to transpose the weight vector.
                weight = parameters[node.input[1]].T
                bias = parameters[node.input[2]]
                in_features = weight.shape[1]
                out_features = weight.shape[0]
                network.add_node(nodes.FullyConnectedNode(f&#34;Linear_{node_index}&#34;, in_features,
                                                          out_features, weight, bias))
            elif node.op_type == &#34;BatchNormalization&#34;:
                # We assume that the real input is always the first element of node.input, the weight tensor
                # is always the second, the bias tensor is always the third, the running_mean always the fourth
                # and the running_var always the fifth.
                num_features = shape_info[node.input[0]][1]
                weight = parameters[node.input[1]]
                bias = parameters[node.input[2]]
                running_mean = parameters[node.input[3]]
                running_var = parameters[node.input[4]]
                # We assume that eps is always the first attribute and momentum is always the second.
                eps = node.attribute[0].f
                momentum = node.attribute[1].f
                network.add_node(nodes.BatchNorm1DNode(f&#34;BatchNorm_{node_index}&#34;, num_features, weight, bias,
                                                       running_mean, running_var, eps, momentum))

            else:
                raise NotImplementedError

            node_index += 1

        return network</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="pynever.strategies.conversion.ConversionStrategy" href="#pynever.strategies.conversion.ConversionStrategy">ConversionStrategy</a></li>
<li>abc.ABC</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="pynever.strategies.conversion.ONNXConverter.from_neural_network"><code class="name flex">
<span>def <span class="ident">from_neural_network</span></span>(<span>self, network: <a title="pynever.networks.NeuralNetwork" href="../networks.html#pynever.networks.NeuralNetwork">NeuralNetwork</a>) ‑> <a title="pynever.strategies.conversion.ONNXNetwork" href="#pynever.strategies.conversion.ONNXNetwork">ONNXNetwork</a></span>
</code></dt>
<dd>
<div class="desc"><p>Convert the neural network of interest to a ONNX representation.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>network</code></strong> :&ensp;<code>NeuralNetwork</code></dt>
<dd>The neural network to convert.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="pynever.strategies.conversion.ONNXNetwork" href="#pynever.strategies.conversion.ONNXNetwork">ONNXNetwork</a></code></dt>
<dd>The ONNX representation resulting from the conversion of the original network.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def from_neural_network(self, network: networks.NeuralNetwork) -&gt; ONNXNetwork:
    &#34;&#34;&#34;
    Convert the neural network of interest to a ONNX representation.

    Parameters
    ----------
    network : NeuralNetwork
        The neural network to convert.

    Returns
    ----------
    ONNXNetwork
        The ONNX representation resulting from the conversion of the original network.

    &#34;&#34;&#34;

    alt_net = None
    for alt_rep in network.alt_rep_cache:
        if isinstance(alt_rep, ONNXNetwork) and alt_rep.up_to_date:
            alt_net = alt_rep

    if alt_net is None:

        if not network.up_to_date:

            for alt_rep in network.alt_rep_cache:

                if alt_rep.up_to_date:

                    if isinstance(alt_rep, PyTorchNetwork):
                        pytorch_cv = PyTorchConverter()
                        network = pytorch_cv.to_neural_network(alt_rep)

                    else:
                        raise NotImplementedError
                    break

        if isinstance(network, networks.SequentialNetwork):

            current_node = None
            previous_output = &#39;X&#39;
            input_info = []
            output_info = []
            initializers = []
            onnx_nodes = []

            while network.get_next_node(current_node) is not None:

                current_node = network.get_next_node(current_node)
                current_input = previous_output

                if network.get_next_node(current_node) is None:
                    current_output = &#39;Y&#39;
                else:
                    current_output = current_node.identifier + &#39;_output&#39;

                if isinstance(current_node, nodes.ReLUNode):

                    input_size = output_size = current_node.num_features
                    input_value_info = onnx.helper.make_tensor_value_info(current_input, onnx.TensorProto.FLOAT,
                                                                          [1, input_size])
                    output_value_info = onnx.helper.make_tensor_value_info(current_output, onnx.TensorProto.FLOAT,
                                                                           [1, output_size])

                    onnx_node = onnx.helper.make_node(
                        &#39;Relu&#39;,
                        inputs=[current_input],
                        outputs=[current_output],
                    )

                    input_info.append(input_value_info)
                    output_info.append(output_value_info)
                    onnx_nodes.append(onnx_node)

                elif isinstance(current_node, nodes.SigmoidNode):

                    input_size = output_size = current_node.num_features
                    input_value_info = onnx.helper.make_tensor_value_info(current_input, onnx.TensorProto.FLOAT,
                                                                          [1, input_size])
                    output_value_info = onnx.helper.make_tensor_value_info(current_output, onnx.TensorProto.FLOAT,
                                                                           [1, output_size])

                    onnx_node = onnx.helper.make_node(
                        &#39;Sigmoid&#39;,
                        inputs=[current_input],
                        outputs=[current_output],
                    )

                    input_info.append(input_value_info)
                    output_info.append(output_value_info)
                    onnx_nodes.append(onnx_node)

                elif isinstance(current_node, nodes.FullyConnectedNode):

                    input_size = current_node.in_features
                    output_size = current_node.out_features

                    input_weight = current_node.identifier + &#34;_weight&#34;
                    input_bias = current_node.identifier + &#34;_bias&#34;

                    input_value_info = onnx.helper.make_tensor_value_info(current_input, onnx.TensorProto.FLOAT,
                                                                          [1, input_size])
                    output_value_info = onnx.helper.make_tensor_value_info(current_output, onnx.TensorProto.FLOAT,
                                                                           [1, output_size])
                    weight_value_info = onnx.helper.make_tensor_value_info(input_weight, onnx.TensorProto.FLOAT,
                                                                           [output_size, input_size])
                    bias_value_info = onnx.helper.make_tensor_value_info(input_bias, onnx.TensorProto.FLOAT,
                                                                         [output_size])

                    # N.B: The Marabou procedure for reading ONNX models do not consider the attributes
                    # transA and transB, therefore we need to transpose the weight vector.
                    weight_tensor = onnx.numpy_helper.from_array(current_node.weight.T, input_weight)
                    bias_tensor = onnx.numpy_helper.from_array(current_node.bias, input_bias)

                    onnx_node = onnx.helper.make_node(
                        &#39;Gemm&#39;,
                        inputs=[current_input, input_weight, input_bias],
                        outputs=[current_output],
                        alpha=1.0,
                        beta=1.0,
                        transA=0,
                        transB=0
                    )

                    input_info.append(input_value_info)
                    input_info.append(weight_value_info)
                    input_info.append(bias_value_info)

                    output_info.append(output_value_info)

                    initializers.append(weight_tensor)
                    initializers.append(bias_tensor)

                    onnx_nodes.append(onnx_node)

                elif isinstance(current_node, nodes.BatchNorm1DNode):

                    input_size = output_size = current_node.num_features

                    input_scale = current_node.identifier + &#34;_scale&#34;
                    input_bias = current_node.identifier + &#34;_bias&#34;
                    input_mean = current_node.identifier + &#34;_mean&#34;
                    input_var = current_node.identifier + &#34;_var&#34;

                    input_value_info = onnx.helper.make_tensor_value_info(current_input, onnx.TensorProto.FLOAT,
                                                                          [1, input_size])
                    output_value_info = onnx.helper.make_tensor_value_info(current_output, onnx.TensorProto.FLOAT,
                                                                           [1, output_size])
                    scale_value_info = onnx.helper.make_tensor_value_info(input_scale, onnx.TensorProto.FLOAT,
                                                                          [input_size])
                    bias_value_info = onnx.helper.make_tensor_value_info(input_bias, onnx.TensorProto.FLOAT,
                                                                         [input_size])
                    mean_value_info = onnx.helper.make_tensor_value_info(input_mean, onnx.TensorProto.FLOAT,
                                                                         [input_size])
                    var_value_info = onnx.helper.make_tensor_value_info(input_var, onnx.TensorProto.FLOAT,
                                                                        [input_size])

                    scale_tensor = onnx.numpy_helper.from_array(current_node.weight, input_scale)
                    bias_tensor = onnx.numpy_helper.from_array(current_node.bias, input_bias)
                    mean_tensor = onnx.numpy_helper.from_array(current_node.running_mean, input_mean)
                    var_tensor = onnx.numpy_helper.from_array(current_node.running_var, input_var)

                    onnx_node = onnx.helper.make_node(
                        &#39;BatchNormalization&#39;,
                        inputs=[current_input, input_scale, input_bias, input_mean, input_var],
                        outputs=[current_output],
                        epsilon=current_node.eps,
                        momentum=current_node.momentum
                    )

                    input_info.append(input_value_info)
                    input_info.append(scale_value_info)
                    input_info.append(bias_value_info)
                    input_info.append(mean_value_info)
                    input_info.append(var_value_info)

                    output_info.append(output_value_info)

                    initializers.append(scale_tensor)
                    initializers.append(bias_tensor)
                    initializers.append(mean_tensor)
                    initializers.append(var_tensor)

                    onnx_nodes.append(onnx_node)

                else:
                    raise NotImplementedError

                previous_output = current_output

            onnx_graph = onnx.helper.make_graph(
                nodes=onnx_nodes,
                name=network.identifier,
                inputs=[input_info[0]],
                outputs=[output_info[-1]],
                initializer=initializers,
                value_info=input_info
            )

            onnx_network = onnx.helper.make_model(graph=onnx_graph)
            alt_net = ONNXNetwork(network.identifier + &#34;_onnx&#34;, onnx_network)

        else:
            raise NotImplementedError

    return alt_net</code></pre>
</details>
</dd>
<dt id="pynever.strategies.conversion.ONNXConverter.to_neural_network"><code class="name flex">
<span>def <span class="ident">to_neural_network</span></span>(<span>self, alt_rep: <a title="pynever.strategies.conversion.ONNXNetwork" href="#pynever.strategies.conversion.ONNXNetwork">ONNXNetwork</a>) ‑> <a title="pynever.networks.NeuralNetwork" href="../networks.html#pynever.networks.NeuralNetwork">NeuralNetwork</a></span>
</code></dt>
<dd>
<div class="desc"><p>Convert the ONNX representation of interest to the internal one.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>alt_rep</code></strong> :&ensp;<code><a title="pynever.strategies.conversion.ONNXNetwork" href="#pynever.strategies.conversion.ONNXNetwork">ONNXNetwork</a></code></dt>
<dd>The ONNX Representation to convert.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>NeuralNetwork</code></dt>
<dd>The Neural Network resulting from the conversion of ONNX Representation.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def to_neural_network(self, alt_rep: ONNXNetwork) -&gt; networks.NeuralNetwork:
    &#34;&#34;&#34;
    Convert the ONNX representation of interest to the internal one.

    Parameters
    ----------
    alt_rep : ONNXNetwork
        The ONNX Representation to convert.

    Returns
    ----------
    NeuralNetwork
        The Neural Network resulting from the conversion of ONNX Representation.

    &#34;&#34;&#34;
    identifier = alt_rep.identifier.replace(&#34;_onnx&#34;, &#34;&#34;)
    network = networks.SequentialNetwork(identifier)

    parameters = {}
    for initializer in alt_rep.onnx_network.graph.initializer:
        parameters[initializer.name] = onnx.numpy_helper.to_array(initializer)

    shape_info = {}
    for value_info in alt_rep.onnx_network.graph.value_info:
        shape = []
        for dim in value_info.type.tensor_type.shape.dim:
            shape.append(dim.dim_value)
        shape_info[value_info.name] = shape

    node_index = 1
    for node in alt_rep.onnx_network.graph.node:

        if node.op_type == &#34;Relu&#34;:

            # We assume that the real input of the node is always the first element of node.input
            # and that the shape is [batch_placeholder, real_size] for the inputs.
            num_features = shape_info[node.input[0]][1]
            network.add_node(nodes.ReLUNode(f&#34;ReLU_{node_index}&#34;, num_features))

        elif node.op_type == &#34;Sigmoid&#34;:
            num_features = shape_info[node.input[0]][1]
            network.add_node(nodes.SigmoidNode(f&#34;Sigmoid_{node_index}&#34;, num_features))

        elif node.op_type == &#34;Gemm&#34;:
            # We assume that the weight tensor is always the second element of node.input and the bias tensor
            # is always the third.
            # N.B: The Marabou procedure for reading ONNX models do not consider the attributes transA and transB,
            # therefore we need to transpose the weight vector.
            weight = parameters[node.input[1]].T
            bias = parameters[node.input[2]]
            in_features = weight.shape[1]
            out_features = weight.shape[0]
            network.add_node(nodes.FullyConnectedNode(f&#34;Linear_{node_index}&#34;, in_features,
                                                      out_features, weight, bias))
        elif node.op_type == &#34;BatchNormalization&#34;:
            # We assume that the real input is always the first element of node.input, the weight tensor
            # is always the second, the bias tensor is always the third, the running_mean always the fourth
            # and the running_var always the fifth.
            num_features = shape_info[node.input[0]][1]
            weight = parameters[node.input[1]]
            bias = parameters[node.input[2]]
            running_mean = parameters[node.input[3]]
            running_var = parameters[node.input[4]]
            # We assume that eps is always the first attribute and momentum is always the second.
            eps = node.attribute[0].f
            momentum = node.attribute[1].f
            network.add_node(nodes.BatchNorm1DNode(f&#34;BatchNorm_{node_index}&#34;, num_features, weight, bias,
                                                   running_mean, running_var, eps, momentum))

        else:
            raise NotImplementedError

        node_index += 1

    return network</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="pynever.strategies.conversion.ONNXNetwork"><code class="flex name class">
<span>class <span class="ident">ONNXNetwork</span></span>
<span>(</span><span>identifier: str, onnx_network: onnx.onnx_ml_pb2.ModelProto, up_to_date: bool = True)</span>
</code></dt>
<dd>
<div class="desc"><p>An class used to represent a ONNX representation for a neural network.</p>
<h2 id="attributes">Attributes</h2>
<dl>
<dt><strong><code>identifier</code></strong> :&ensp;<code>str</code></dt>
<dd>identifier for the alternative representation</dd>
<dt><strong><code>onnx_network</code></strong> :&ensp;<code>onnx.ModelProto</code></dt>
<dd>Real ONNX network.</dd>
<dt><strong><code>up_to_date</code></strong> :&ensp;<code>bool</code></dt>
<dd>flag which indicates if the alternative representation is up to date with respect
to the internal representation of the network (optional: True).</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class ONNXNetwork(AlternativeRepresentation):
    &#34;&#34;&#34;
    An class used to represent a ONNX representation for a neural network.

    Attributes
    ----------
    identifier : str
        identifier for the alternative representation
    onnx_network : onnx.ModelProto
        Real ONNX network.
    up_to_date : bool
        flag which indicates if the alternative representation is up to date with respect
        to the internal representation of the network (optional: True).

    &#34;&#34;&#34;

    def __init__(self, identifier: str, onnx_network: onnx.ModelProto, up_to_date: bool = True):
        super().__init__(identifier, up_to_date)
        self.onnx_network = copy.deepcopy(onnx_network)</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="pynever.strategies.conversion.AlternativeRepresentation" href="#pynever.strategies.conversion.AlternativeRepresentation">AlternativeRepresentation</a></li>
<li>abc.ABC</li>
</ul>
</dd>
<dt id="pynever.strategies.conversion.PyTorchConverter"><code class="flex name class">
<span>class <span class="ident">PyTorchConverter</span></span>
</code></dt>
<dd>
<div class="desc"><p>A class used to represent the conversion strategy for PyTorch models.</p>
<h2 id="methods">Methods</h2>
<p>from_neural_network(NeuralNetwork)
Convert the neural network of interest to a PyTorchNetwork model.
to_neural_network(PyTorchNetwork)
Convert the PyTorchNetwork of interest to our internal representation of a Neural Network.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class PyTorchConverter(ConversionStrategy):
    &#34;&#34;&#34;
    A class used to represent the conversion strategy for PyTorch models.

    Methods
    ----------
    from_neural_network(NeuralNetwork)
        Convert the neural network of interest to a PyTorchNetwork model.
    to_neural_network(PyTorchNetwork)
        Convert the PyTorchNetwork of interest to our internal representation of a Neural Network.

    &#34;&#34;&#34;

    def from_neural_network(self, network: networks.NeuralNetwork) -&gt; PyTorchNetwork:
        &#34;&#34;&#34;
        Convert the neural network of interest to a PyTorch representation.

        Parameters
        ----------
        network : NeuralNetwork
            The neural network to convert.

        Returns
        ----------
        PyTorchNetwork
            The PyTorch representation resulting from the conversion of the original network.

        &#34;&#34;&#34;

        alt_net = None
        pytorch_network = None
        for alt_rep in network.alt_rep_cache:
            if isinstance(alt_rep, PyTorchNetwork) and alt_rep.up_to_date:
                alt_net = alt_rep

        if alt_net is None:

            if not network.up_to_date:

                for alt_rep in network.alt_rep_cache:

                    if alt_rep.up_to_date:

                        if isinstance(alt_rep, ONNXNetwork):
                            onnx_cv = ONNXConverter()
                            network = onnx_cv.to_neural_network(alt_rep)

                        else:
                            raise NotImplementedError
                        break

            if isinstance(network, networks.SequentialNetwork):
                pytorch_layers = []
                for layer in network.nodes.values():

                    new_layer = None
                    if isinstance(layer, nodes.ReLUNode):
                        new_layer = torch.nn.ReLU()

                    elif isinstance(layer, nodes.SigmoidNode):
                        new_layer = torch.nn.Sigmoid()

                    elif isinstance(layer, nodes.FullyConnectedNode):

                        if layer.bias is not None:
                            has_bias = True
                        else:
                            has_bias = False

                        new_layer = torch.nn.Linear(in_features=layer.in_features,
                                                    out_features=layer.out_features,
                                                    bias=has_bias)

                        weight = torch.from_numpy(layer.weight)
                        new_layer.weight.data = weight

                        if has_bias:
                            bias = torch.from_numpy(layer.bias)
                            new_layer.bias.data = bias

                    elif isinstance(layer, nodes.BatchNorm1DNode):

                        new_layer = torch.nn.BatchNorm1d(num_features=layer.num_features,
                                                         eps=layer.eps, momentum=layer.momentum,
                                                         affine=layer.affine,
                                                         track_running_stats=layer.track_running_stats)

                        new_layer.weight.data = torch.from_numpy(layer.weight)
                        new_layer.bias.data = torch.from_numpy(layer.bias)
                        new_layer.running_mean.data = torch.from_numpy(layer.running_mean)
                        new_layer.running_var.data = torch.from_numpy(layer.running_var)

                    if new_layer is not None:
                        pytorch_layers.append(new_layer)

                pytorch_network = torch.nn.Sequential(*pytorch_layers)

            if alt_net is None and pytorch_network is None:
                print(&#34;WARNING: network to convert is not valid, the alternative representation is None&#34;)

            identifier = network.identifier + &#39;_pytorch&#39;
            alt_net = PyTorchNetwork(identifier=identifier, pytorch_network=pytorch_network)

        return alt_net

    def to_neural_network(self, alt_rep: PyTorchNetwork) -&gt; networks.NeuralNetwork:
        &#34;&#34;&#34;
        Convert the PyTorch representation of interest to the internal one.

        Parameters
        ----------
        alt_rep : PyTorchNetwork
            The PyTorch Representation to convert.

        Returns
        ----------
        NeuralNetwork
            The Neural Network resulting from the conversion of PyTorch Representation.

        &#34;&#34;&#34;

        identifier = alt_rep.identifier.replace(&#39;_pytorch&#39;, &#39;&#39;)
        network = networks.SequentialNetwork(identifier=identifier)

        node_index = 0
        size_prev_output = 0
        alt_rep.pytorch_network.cpu()
        for m in alt_rep.pytorch_network.modules():

            new_node = None

            if isinstance(m, torch.nn.ReLU):
                new_node = nodes.ReLUNode(identifier=&#39;ReLU_{}&#39;.format(node_index), num_features=size_prev_output)

            elif isinstance(m, torch.nn.Sigmoid):
                new_node = nodes.SigmoidNode(identifier=&#39;Sigmoid_{}&#39;.format(node_index), num_features=size_prev_output)

            elif isinstance(m, torch.nn.Linear):
                in_features = m.in_features
                out_features = m.out_features
                weight = m.weight.detach().numpy()
                bias = m.bias.detach().numpy()
                new_node = nodes.FullyConnectedNode(identifier=&#39;FullyConnected_{}&#39;.format(node_index),
                                                    in_features=in_features, out_features=out_features,
                                                    weight=weight, bias=bias)

                size_prev_output = out_features

            elif isinstance(m, torch.nn.BatchNorm1d):

                num_features = m.num_features
                eps = m.eps
                momentum = m.momentum
                track_running_stats = m.track_running_stats
                affine = m.affine

                weight = m.weight.detach().numpy()
                bias = m.bias.detach().numpy()
                running_mean = m.running_mean.numpy()
                running_var = m.running_var.numpy()

                new_node = nodes.BatchNorm1DNode(identifier=&#39;BatchNorm1D_{}&#39;.format(node_index),
                                                 num_features=num_features, weight=weight, bias=bias,
                                                 running_mean=running_mean, running_var=running_var, eps=eps,
                                                 momentum=momentum, affine=affine,
                                                 track_running_stats=track_running_stats)

                size_prev_output = num_features

            if new_node is not None:
                node_index += 1
                network.add_node(new_node)

        return network</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="pynever.strategies.conversion.ConversionStrategy" href="#pynever.strategies.conversion.ConversionStrategy">ConversionStrategy</a></li>
<li>abc.ABC</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="pynever.strategies.conversion.PyTorchConverter.from_neural_network"><code class="name flex">
<span>def <span class="ident">from_neural_network</span></span>(<span>self, network: <a title="pynever.networks.NeuralNetwork" href="../networks.html#pynever.networks.NeuralNetwork">NeuralNetwork</a>) ‑> <a title="pynever.strategies.conversion.PyTorchNetwork" href="#pynever.strategies.conversion.PyTorchNetwork">PyTorchNetwork</a></span>
</code></dt>
<dd>
<div class="desc"><p>Convert the neural network of interest to a PyTorch representation.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>network</code></strong> :&ensp;<code>NeuralNetwork</code></dt>
<dd>The neural network to convert.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="pynever.strategies.conversion.PyTorchNetwork" href="#pynever.strategies.conversion.PyTorchNetwork">PyTorchNetwork</a></code></dt>
<dd>The PyTorch representation resulting from the conversion of the original network.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def from_neural_network(self, network: networks.NeuralNetwork) -&gt; PyTorchNetwork:
    &#34;&#34;&#34;
    Convert the neural network of interest to a PyTorch representation.

    Parameters
    ----------
    network : NeuralNetwork
        The neural network to convert.

    Returns
    ----------
    PyTorchNetwork
        The PyTorch representation resulting from the conversion of the original network.

    &#34;&#34;&#34;

    alt_net = None
    pytorch_network = None
    for alt_rep in network.alt_rep_cache:
        if isinstance(alt_rep, PyTorchNetwork) and alt_rep.up_to_date:
            alt_net = alt_rep

    if alt_net is None:

        if not network.up_to_date:

            for alt_rep in network.alt_rep_cache:

                if alt_rep.up_to_date:

                    if isinstance(alt_rep, ONNXNetwork):
                        onnx_cv = ONNXConverter()
                        network = onnx_cv.to_neural_network(alt_rep)

                    else:
                        raise NotImplementedError
                    break

        if isinstance(network, networks.SequentialNetwork):
            pytorch_layers = []
            for layer in network.nodes.values():

                new_layer = None
                if isinstance(layer, nodes.ReLUNode):
                    new_layer = torch.nn.ReLU()

                elif isinstance(layer, nodes.SigmoidNode):
                    new_layer = torch.nn.Sigmoid()

                elif isinstance(layer, nodes.FullyConnectedNode):

                    if layer.bias is not None:
                        has_bias = True
                    else:
                        has_bias = False

                    new_layer = torch.nn.Linear(in_features=layer.in_features,
                                                out_features=layer.out_features,
                                                bias=has_bias)

                    weight = torch.from_numpy(layer.weight)
                    new_layer.weight.data = weight

                    if has_bias:
                        bias = torch.from_numpy(layer.bias)
                        new_layer.bias.data = bias

                elif isinstance(layer, nodes.BatchNorm1DNode):

                    new_layer = torch.nn.BatchNorm1d(num_features=layer.num_features,
                                                     eps=layer.eps, momentum=layer.momentum,
                                                     affine=layer.affine,
                                                     track_running_stats=layer.track_running_stats)

                    new_layer.weight.data = torch.from_numpy(layer.weight)
                    new_layer.bias.data = torch.from_numpy(layer.bias)
                    new_layer.running_mean.data = torch.from_numpy(layer.running_mean)
                    new_layer.running_var.data = torch.from_numpy(layer.running_var)

                if new_layer is not None:
                    pytorch_layers.append(new_layer)

            pytorch_network = torch.nn.Sequential(*pytorch_layers)

        if alt_net is None and pytorch_network is None:
            print(&#34;WARNING: network to convert is not valid, the alternative representation is None&#34;)

        identifier = network.identifier + &#39;_pytorch&#39;
        alt_net = PyTorchNetwork(identifier=identifier, pytorch_network=pytorch_network)

    return alt_net</code></pre>
</details>
</dd>
<dt id="pynever.strategies.conversion.PyTorchConverter.to_neural_network"><code class="name flex">
<span>def <span class="ident">to_neural_network</span></span>(<span>self, alt_rep: <a title="pynever.strategies.conversion.PyTorchNetwork" href="#pynever.strategies.conversion.PyTorchNetwork">PyTorchNetwork</a>) ‑> <a title="pynever.networks.NeuralNetwork" href="../networks.html#pynever.networks.NeuralNetwork">NeuralNetwork</a></span>
</code></dt>
<dd>
<div class="desc"><p>Convert the PyTorch representation of interest to the internal one.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>alt_rep</code></strong> :&ensp;<code><a title="pynever.strategies.conversion.PyTorchNetwork" href="#pynever.strategies.conversion.PyTorchNetwork">PyTorchNetwork</a></code></dt>
<dd>The PyTorch Representation to convert.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>NeuralNetwork</code></dt>
<dd>The Neural Network resulting from the conversion of PyTorch Representation.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def to_neural_network(self, alt_rep: PyTorchNetwork) -&gt; networks.NeuralNetwork:
    &#34;&#34;&#34;
    Convert the PyTorch representation of interest to the internal one.

    Parameters
    ----------
    alt_rep : PyTorchNetwork
        The PyTorch Representation to convert.

    Returns
    ----------
    NeuralNetwork
        The Neural Network resulting from the conversion of PyTorch Representation.

    &#34;&#34;&#34;

    identifier = alt_rep.identifier.replace(&#39;_pytorch&#39;, &#39;&#39;)
    network = networks.SequentialNetwork(identifier=identifier)

    node_index = 0
    size_prev_output = 0
    alt_rep.pytorch_network.cpu()
    for m in alt_rep.pytorch_network.modules():

        new_node = None

        if isinstance(m, torch.nn.ReLU):
            new_node = nodes.ReLUNode(identifier=&#39;ReLU_{}&#39;.format(node_index), num_features=size_prev_output)

        elif isinstance(m, torch.nn.Sigmoid):
            new_node = nodes.SigmoidNode(identifier=&#39;Sigmoid_{}&#39;.format(node_index), num_features=size_prev_output)

        elif isinstance(m, torch.nn.Linear):
            in_features = m.in_features
            out_features = m.out_features
            weight = m.weight.detach().numpy()
            bias = m.bias.detach().numpy()
            new_node = nodes.FullyConnectedNode(identifier=&#39;FullyConnected_{}&#39;.format(node_index),
                                                in_features=in_features, out_features=out_features,
                                                weight=weight, bias=bias)

            size_prev_output = out_features

        elif isinstance(m, torch.nn.BatchNorm1d):

            num_features = m.num_features
            eps = m.eps
            momentum = m.momentum
            track_running_stats = m.track_running_stats
            affine = m.affine

            weight = m.weight.detach().numpy()
            bias = m.bias.detach().numpy()
            running_mean = m.running_mean.numpy()
            running_var = m.running_var.numpy()

            new_node = nodes.BatchNorm1DNode(identifier=&#39;BatchNorm1D_{}&#39;.format(node_index),
                                             num_features=num_features, weight=weight, bias=bias,
                                             running_mean=running_mean, running_var=running_var, eps=eps,
                                             momentum=momentum, affine=affine,
                                             track_running_stats=track_running_stats)

            size_prev_output = num_features

        if new_node is not None:
            node_index += 1
            network.add_node(new_node)

    return network</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="pynever.strategies.conversion.PyTorchNetwork"><code class="flex name class">
<span>class <span class="ident">PyTorchNetwork</span></span>
<span>(</span><span>identifier: str, pytorch_network: torch.nn.modules.module.Module, up_to_date: bool = True)</span>
</code></dt>
<dd>
<div class="desc"><p>An class used to represent a PyTorch representation for a neural network.</p>
<h2 id="attributes">Attributes</h2>
<dl>
<dt><strong><code>identifier</code></strong> :&ensp;<code>str</code></dt>
<dd>identifier for the alternative representation</dd>
<dt><strong><code>pytorch_network</code></strong> :&ensp;<code>torch.nn.Module</code></dt>
<dd>Real PyTorch network.</dd>
<dt><strong><code>up_to_date</code></strong> :&ensp;<code>bool</code></dt>
<dd>flag which indicates if the alternative representation is up to date with respect
to the internal representation of the network (optional: True).</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class PyTorchNetwork(AlternativeRepresentation):
    &#34;&#34;&#34;
    An class used to represent a PyTorch representation for a neural network.

    Attributes
    ----------
    identifier : str
        identifier for the alternative representation
    pytorch_network : torch.nn.Module
        Real PyTorch network.
    up_to_date : bool
        flag which indicates if the alternative representation is up to date with respect
        to the internal representation of the network (optional: True).

    &#34;&#34;&#34;
    def __init__(self, identifier: str, pytorch_network: torch.nn.Module, up_to_date: bool = True):
        super().__init__(identifier, up_to_date)
        self.pytorch_network = copy.deepcopy(pytorch_network)</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="pynever.strategies.conversion.AlternativeRepresentation" href="#pynever.strategies.conversion.AlternativeRepresentation">AlternativeRepresentation</a></li>
<li>abc.ABC</li>
</ul>
</dd>
<dt id="pynever.strategies.conversion.TensorflowConverter"><code class="flex name class">
<span>class <span class="ident">TensorflowConverter</span></span>
</code></dt>
<dd>
<div class="desc"><p>A class used to represent the conversion strategy for Tensorflow models.</p>
<h2 id="methods">Methods</h2>
<p>from_neural_network(NeuralNetwork)
Convert the neural network of interest to a TensorflowNetwork model.
to_neural_network(ONNXNetwork)
Convert the TensorflowNetwork of interest to our internal representation of a Neural Network.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class TensorflowConverter(ConversionStrategy):
    &#34;&#34;&#34;
    A class used to represent the conversion strategy for Tensorflow models.

    Methods
    ----------
    from_neural_network(NeuralNetwork)
        Convert the neural network of interest to a TensorflowNetwork model.
    to_neural_network(ONNXNetwork)
        Convert the TensorflowNetwork of interest to our internal representation of a Neural Network.

    &#34;&#34;&#34;

    def from_neural_network(self, network: networks.NeuralNetwork) -&gt; TensorflowNetwork:
        &#34;&#34;&#34;
        Convert the neural network of interest to a Tensorflow representation.

        Parameters
        ----------
        network : NeuralNetwork
            The neural network to convert.

        Returns
        ----------
        TensorflowNetwork
            The Tensorflow representation resulting from the conversion of the original network.

        &#34;&#34;&#34;

    def to_neural_network(self, alt_rep: TensorflowNetwork) -&gt; networks.NeuralNetwork:
        &#34;&#34;&#34;
        Convert the Tensorflow representation of interest to the internal one.

        Parameters
        ----------
        alt_rep : TensorflowNetwork
            The Tensorflow Representation to convert.

        Returns
        ----------
        NeuralNetwork
            The Neural Network resulting from the conversion of Tensorflow Representation.

        &#34;&#34;&#34;</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="pynever.strategies.conversion.ConversionStrategy" href="#pynever.strategies.conversion.ConversionStrategy">ConversionStrategy</a></li>
<li>abc.ABC</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="pynever.strategies.conversion.TensorflowConverter.from_neural_network"><code class="name flex">
<span>def <span class="ident">from_neural_network</span></span>(<span>self, network: <a title="pynever.networks.NeuralNetwork" href="../networks.html#pynever.networks.NeuralNetwork">NeuralNetwork</a>) ‑> <a title="pynever.strategies.conversion.TensorflowNetwork" href="#pynever.strategies.conversion.TensorflowNetwork">TensorflowNetwork</a></span>
</code></dt>
<dd>
<div class="desc"><p>Convert the neural network of interest to a Tensorflow representation.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>network</code></strong> :&ensp;<code>NeuralNetwork</code></dt>
<dd>The neural network to convert.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="pynever.strategies.conversion.TensorflowNetwork" href="#pynever.strategies.conversion.TensorflowNetwork">TensorflowNetwork</a></code></dt>
<dd>The Tensorflow representation resulting from the conversion of the original network.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def from_neural_network(self, network: networks.NeuralNetwork) -&gt; TensorflowNetwork:
    &#34;&#34;&#34;
    Convert the neural network of interest to a Tensorflow representation.

    Parameters
    ----------
    network : NeuralNetwork
        The neural network to convert.

    Returns
    ----------
    TensorflowNetwork
        The Tensorflow representation resulting from the conversion of the original network.

    &#34;&#34;&#34;</code></pre>
</details>
</dd>
<dt id="pynever.strategies.conversion.TensorflowConverter.to_neural_network"><code class="name flex">
<span>def <span class="ident">to_neural_network</span></span>(<span>self, alt_rep: <a title="pynever.strategies.conversion.TensorflowNetwork" href="#pynever.strategies.conversion.TensorflowNetwork">TensorflowNetwork</a>) ‑> <a title="pynever.networks.NeuralNetwork" href="../networks.html#pynever.networks.NeuralNetwork">NeuralNetwork</a></span>
</code></dt>
<dd>
<div class="desc"><p>Convert the Tensorflow representation of interest to the internal one.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>alt_rep</code></strong> :&ensp;<code><a title="pynever.strategies.conversion.TensorflowNetwork" href="#pynever.strategies.conversion.TensorflowNetwork">TensorflowNetwork</a></code></dt>
<dd>The Tensorflow Representation to convert.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>NeuralNetwork</code></dt>
<dd>The Neural Network resulting from the conversion of Tensorflow Representation.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def to_neural_network(self, alt_rep: TensorflowNetwork) -&gt; networks.NeuralNetwork:
    &#34;&#34;&#34;
    Convert the Tensorflow representation of interest to the internal one.

    Parameters
    ----------
    alt_rep : TensorflowNetwork
        The Tensorflow Representation to convert.

    Returns
    ----------
    NeuralNetwork
        The Neural Network resulting from the conversion of Tensorflow Representation.

    &#34;&#34;&#34;</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="pynever.strategies.conversion.TensorflowNetwork"><code class="flex name class">
<span>class <span class="ident">TensorflowNetwork</span></span>
<span>(</span><span>identifier: str, up_to_date: bool = True)</span>
</code></dt>
<dd>
<div class="desc"><p>An class used to represent a Tensorflow representation for a neural network.</p>
<h2 id="attributes">Attributes</h2>
<dl>
<dt><strong><code>identifier</code></strong> :&ensp;<code>str</code></dt>
<dd>identifier for the alternative representation</dd>
<dt><strong><code>up_to_date</code></strong> :&ensp;<code>bool</code></dt>
<dd>flag which indicates if the alternative representation is up to date with respect
to the internal representation of the network (optional: True).</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class TensorflowNetwork(AlternativeRepresentation):
    &#34;&#34;&#34;
    An class used to represent a Tensorflow representation for a neural network.

    Attributes
    ----------
    identifier : str
        identifier for the alternative representation
    up_to_date : bool
        flag which indicates if the alternative representation is up to date with respect
        to the internal representation of the network (optional: True).

    &#34;&#34;&#34;
    def __init__(self, identifier: str, up_to_date: bool = True):
        super().__init__(identifier, up_to_date)</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="pynever.strategies.conversion.AlternativeRepresentation" href="#pynever.strategies.conversion.AlternativeRepresentation">AlternativeRepresentation</a></li>
<li>abc.ABC</li>
</ul>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="pynever.strategies" href="index.html">pynever.strategies</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="pynever.strategies.conversion.AlternativeRepresentation" href="#pynever.strategies.conversion.AlternativeRepresentation">AlternativeRepresentation</a></code></h4>
</li>
<li>
<h4><code><a title="pynever.strategies.conversion.ConversionStrategy" href="#pynever.strategies.conversion.ConversionStrategy">ConversionStrategy</a></code></h4>
<ul class="">
<li><code><a title="pynever.strategies.conversion.ConversionStrategy.from_neural_network" href="#pynever.strategies.conversion.ConversionStrategy.from_neural_network">from_neural_network</a></code></li>
<li><code><a title="pynever.strategies.conversion.ConversionStrategy.to_neural_network" href="#pynever.strategies.conversion.ConversionStrategy.to_neural_network">to_neural_network</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pynever.strategies.conversion.ONNXConverter" href="#pynever.strategies.conversion.ONNXConverter">ONNXConverter</a></code></h4>
<ul class="">
<li><code><a title="pynever.strategies.conversion.ONNXConverter.from_neural_network" href="#pynever.strategies.conversion.ONNXConverter.from_neural_network">from_neural_network</a></code></li>
<li><code><a title="pynever.strategies.conversion.ONNXConverter.to_neural_network" href="#pynever.strategies.conversion.ONNXConverter.to_neural_network">to_neural_network</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pynever.strategies.conversion.ONNXNetwork" href="#pynever.strategies.conversion.ONNXNetwork">ONNXNetwork</a></code></h4>
</li>
<li>
<h4><code><a title="pynever.strategies.conversion.PyTorchConverter" href="#pynever.strategies.conversion.PyTorchConverter">PyTorchConverter</a></code></h4>
<ul class="">
<li><code><a title="pynever.strategies.conversion.PyTorchConverter.from_neural_network" href="#pynever.strategies.conversion.PyTorchConverter.from_neural_network">from_neural_network</a></code></li>
<li><code><a title="pynever.strategies.conversion.PyTorchConverter.to_neural_network" href="#pynever.strategies.conversion.PyTorchConverter.to_neural_network">to_neural_network</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pynever.strategies.conversion.PyTorchNetwork" href="#pynever.strategies.conversion.PyTorchNetwork">PyTorchNetwork</a></code></h4>
</li>
<li>
<h4><code><a title="pynever.strategies.conversion.TensorflowConverter" href="#pynever.strategies.conversion.TensorflowConverter">TensorflowConverter</a></code></h4>
<ul class="">
<li><code><a title="pynever.strategies.conversion.TensorflowConverter.from_neural_network" href="#pynever.strategies.conversion.TensorflowConverter.from_neural_network">from_neural_network</a></code></li>
<li><code><a title="pynever.strategies.conversion.TensorflowConverter.to_neural_network" href="#pynever.strategies.conversion.TensorflowConverter.to_neural_network">to_neural_network</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pynever.strategies.conversion.TensorflowNetwork" href="#pynever.strategies.conversion.TensorflowNetwork">TensorflowNetwork</a></code></h4>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>